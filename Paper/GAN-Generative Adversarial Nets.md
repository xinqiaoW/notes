---
share_link: https://share.note.sx/1pj1ptk2#q18zKrcT0OHheQzG7epdtq3zUrGQ5utqNGyrdq6A9D0
share_updated: 2024-12-03T13:03:47+08:00
---
[Generative Adversarial Nets](https://arxiv.org/pdf/1406.2661)

生成对抗网络分为两部分，判别器（discriminator）和生成器（generator）。生成器的目标是生成内容，使得判别器无法分辨该内容是源于真实数据还是生成器生成的虚假数据。判别器的目标是尽可能成功地分辨数据是真是假。

我们可以用$$\mathbb{E}_{z \textasciitilde P(z)}log(D(G(z)))$$来衡量生成器的能力。

我们可以用$$\mathbb{E}_{x \textasciitilde data}log(D(x)) + \mathbb{E}_{z\textasciitilde p(z)}log(1 - D[G(z)])$$
来衡量判别器的能力。

所以我们的目标是最大化上面两个函数，我们希望的是无论是生成器还是判别器都能起到比较好的效果。

我们只需要将损失函数定义为上面两个能力函数的相反数，并借助反向传播梯度下降，使得损失函数优化得最低（能力函数最高）即可。（数学期望-->我们可以用批量平均来处理。）

（除此之外，我们还可以定义各种各样的损失函数，例如
![[Pasted image 20241127121445.png]]
 ）
 我们每次利用生成器生成 batch_size 张图片，随后将 batch_size 张假图片和batch_size 张真图片交给判别器进行打分。计算判别器的损失，更新判别器，再重生成 batch_size 张假图片，交给判别器打分，计算生成器的损失，更新生成器。
 
刚开始假图片和真图片区别很大，为了更好地分辨真假图片，判别器会试着去学到一些特征分辨真假，而当判别器的能力提升后，生成器会去试图蒙蔽判别器，从而去模仿判别器学习到的真图片的特征，使得我们的生成器可以生成比较逼真的图像。因此，在训练过程中判别器和生成器损失均减小是我们希望看到的。如果只有生成器损失减小，说明生成器蒙蔽的是一个没什么用的判别器，那么生成器的图片未必真实。




