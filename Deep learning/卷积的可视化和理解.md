---
share_link: https://share.note.sx/48gf5n11#ZdQesuFxRrycbqcP/aBUoDuZ9MmCmFrrQ5vVn5MGjUo
share_updated: 2024-12-03T13:02:55+08:00
---
卷积的第一层权重的可视化：
	由于卷积的第一层直接和原图做内积，我们可以看作卷积核在寻找和其权重类似的图像并赋予高响应，将卷积核可视化出来，我们可以在一定程度上知道卷积核在寻找什么。
	下面是可视化结果：
	![[Pasted image 20241125122656.png]]
	我们可以发现，第一层卷积核寻找的是有向边，纹理等一些基础的特征。

显著图（Saliency map）：
	我们可以通过计算某个神经元，或某一类的 score 对某张图片每个像素的梯度，梯度越大，说明该像素对最后 score （或者某一个神经元的分数）的影响也就越大，也就是神经网络更加关注的信息。如下图：
	![[Pasted image 20241125123428.png]]
	我们可以发现，神经网络的确关注到了小车，海洋生物等关键实体。

遮挡实验（Occlusion Experiment）：
	随机遮挡图片一部分，记录预测概率，绘制热力图（Heat Map），观察遮挡位置和预测概率的关系。
	![[Pasted image 20241125123828.png]]
	例如：我们可以发现，遮住帆船后，预测正确类的概率直线下降，说明神经网络是通过帆船来预测的。

梯度上升找到最大响应图像：
	我们把图片当作要训练的参数，利用梯度上升找到使得某一类 score 最高的图片，也就是神经网络认为的最符合某一类的图片，通过这张图片也许我们能发现神经网络在寻找什么。

近邻法：
	由于原图的像素没有什么语义信息，所以我们可以试着把 CNN 最后的特征向量拿出来做紧邻，下面是效果：
	![[Pasted image 20241125124538.png]]
