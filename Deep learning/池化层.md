---
share_link: https://share.note.sx/thdmzk08#+xLhD3u3fk2jqRWz9nemW7vMxyevN5GyFZ+saFxLFbA
share_updated: 2024-11-27T20:18:12+08:00
---
**主要内容** pytorch中默认池化是不重叠的，如果我们想要重叠，我们需要设定stride。pytorch中池化层在每个输入通道上单独运算。

- 代码部分

1 - 构建池化层并检验
```
def max_pool2d(X, pool_size):  
    h, w = X.shape  
    Y = torch.zeros(size=(h - pool_size + 1, w - pool_size + 1))  
    for i in range(Y.shape[0]):  
        for j in range(Y.shape[1]):  
            Y[i, j] = X[i:i+pool_size, j:j+pool_size].max()  
    return Y  
  
  
# 检验池化函数的正确性  
X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])  
print(max_pool2d(X, pool_size=2))
```
2 - 使用框架中的池化层
```
X = torch.arange(16).reshape((1, 1, 4, 4))  
pool2d = nn.MaxPool2d(3, stride=1)  
print(pool2d(X))  
  
# 池化层在每个输入通道上单独运算  
X = torch.cat((X, X + 1), dim=1)  
print(pool2d(X))
```
