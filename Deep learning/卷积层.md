---
share_link: https://share.note.sx/ihqiwwz4#NHZFiLvc53d8LeMd8tcS56/7GD99aclVtjP0t/piaUU
share_updated: 2024-12-03T13:02:35+08:00
---
**主要内容** 我简单实现了一下卷积层，并利用垂直边缘做例子，检验了一下卷积层的效果。这里我更新参数时，并未使用pytorch的trainer.step()，而是利用了variable.weght.data去访问权重的值，并利用variable.weight.grad去更新参数，pytorch默认卷积的stride=1，如果有需要可以调整。

- 代码：

1 - 导入必要的包和库
2 - 构建二维互相运算
```
def corr2d(X, K):  
    h, w = K.shape  
    Y = torch.zeros(size=(X.shape[0] - h + 1, X.shape[1] - w + 1))  
    for i in range(Y.shape[0]):  
        for j in range(Y.shape[1]):  
            Y[i, j] = (X[i:i + h, j:j+w] * K).sum()  
    return Y
```
3 - 实现二维卷积层类
```
class Conv2d(nn.Module):  
    def __init__(self, kernel_size):  
        self.weight = nn.Parameter(torch.rand(kernel_size))  
        self.bias = nn.Parameter(torch.zeros(1))  
  
    def forward(self, x):  
        return corr2d(x, self.weight) + self.bias
```
4 - 以垂直边缘检测为例
```
X = torch.ones(size=(6, 8))  
X[:, 2:6] = 0  
K = torch.tensor([[1, -1]])  
Y = corr2d(X, K)  
  
net = nn.Conv2d(1, 1, kernel_size=(1, 2))  
X = X.reshape((1, 1, 6, 8))  
Y = Y.reshape((1, 1, 6, 7))  
for i in range(10):  
    prediction = net(X)  
    loss = ((prediction - Y) ** 2).sum()  
    net.zero_grad()  
    loss.backward()  
    net.weight.data[:] -= 3e-2 * net.weight.grad  
    print(loss)
```

